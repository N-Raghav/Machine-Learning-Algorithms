{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks from scratch\n"
      ],
      "metadata": {
        "id": "-DNIi7n4xrXd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SDVbGThdxgt4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "bPUuD3Z_xoTY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "WFIEJRe2xoVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "1e3b2e11-543d-4237-a8a8-4aa4340d5807"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "1       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "2       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "3       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "4       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "\n",
              "   pixel780  pixel781  pixel782  pixel783  \n",
              "0       0.0       0.0       0.0       0.0  \n",
              "1       0.0       0.0       0.0       0.0  \n",
              "2       0.0       0.0       0.0       0.0  \n",
              "3       0.0       0.0       0.0       0.0  \n",
              "4       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4cc180d-becf-47f1-936e-7d70a5472c01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4cc180d-becf-47f1-936e-7d70a5472c01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4cc180d-becf-47f1-936e-7d70a5472c01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4cc180d-becf-47f1-936e-7d70a5472c01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-704fff88-5d85-468a-9294-c31d9de4e45e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-704fff88-5d85-468a-9294-c31d9de4e45e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-704fff88-5d85-468a-9294-c31d9de4e45e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "mUA8fzz1xoYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc929fe-77c7-4149-ca6d-379feaf21f10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2290 entries, 0 to 2289\n",
            "Columns: 785 entries, label to pixel783\n",
            "dtypes: float64(215), int64(570)\n",
            "memory usage: 13.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=np.array(data)\n",
        "m,n=data.shape\n",
        "np.random.shuffle(data)\n",
        "#This split of the train.csv is to avoid over-fitting test data\n",
        "data_dev=data[0:1000].T\n",
        "Y_dev=data_dev[0]\n",
        "X_dev=data_dev[1:n]\n",
        "X_dev = X_dev / 255.\n",
        "\n",
        "data_train=data[1000:m].T\n",
        "Y_train=data_train[0]\n",
        "X_train=data_train[1:n]\n",
        "X_train = X_train / 255.\n",
        "_,m_train = X_train.shape"
      ],
      "metadata": {
        "id": "FaUNJOnK-HsA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yxeyiWz-hfO",
        "outputId": "cc69b2f9-468a-4b2a-e993-a3ae65a44ff6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1290,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6XSpbRAZ5vh",
        "outputId": "7323dce1-20f4-4602-c2cd-11f68bf241ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 1290)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fjWcglSOdmP",
        "outputId": "23866225-51e1-4e87-9d28-5da2a16e8d75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 1290)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "  W1=np.random.rand(10,784) - 0.5\n",
        "  b1=np.random.rand(10,1) - 0.5\n",
        "  W2=np.random.rand(10,10) - 0.5\n",
        "  b2=np.random.rand(10,1) - 0.5\n",
        "  return W1,b1,W2,b2\n",
        "\n",
        "def ReLu(Z):\n",
        "  return np.maximum(Z,0)\n",
        "\n",
        "def deriv_ReLu(Z):\n",
        "  return Z > 0\n",
        "\n",
        "def softmax(Z):\n",
        "  A = np.exp(Z)/np.sum(np.exp(Z),axis=0,keepdims=True)\n",
        "  return A\n",
        "\n",
        "def forward_prop(W1,b1,W2,b2,X):\n",
        "  Z1=W1.dot(X) + b1\n",
        "  A1=ReLu(Z1)\n",
        "  Z2=W2.dot(A1)+b2\n",
        "  A2=softmax(Z2)\n",
        "  return Z1,A1,Z2,A2\n",
        "\n",
        "#setting the index of the label to 1\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, int(Y.max()) + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y.astype(int)] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "def back_prop(A1,A2,Y,W1,Z1,W2,Z2,X):\n",
        "  one_hot_Y=one_hot(Y)\n",
        "  dZ2= A2 - one_hot_Y\n",
        "  dW2= 1/m * dZ2.dot(A1.T)\n",
        "  db2 = (1 / m) * np.sum(dZ2)\n",
        "  dZ1= W2.T.dot(dZ2) *  deriv_ReLu(Z1)\n",
        "  dW1= 1/m * dZ1.dot(X.T)\n",
        "  db1 = (1 / m) * np.sum(dZ1)\n",
        "  return dW1,db1,dW2,db2\n",
        "\n",
        "def update_params(dW1,db1,dW2,db2,W1,W2,b1,b2,alpha):\n",
        "  W1= W1 - alpha * dW1\n",
        "  b1= b1 - alpha * db1\n",
        "  W2= W2 - alpha * dW2\n",
        "  b2= b2 - alpha * db2\n",
        "  return W1, b1 , W2, b2\n"
      ],
      "metadata": {
        "id": "KhBHG4ux_dRe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "  return np.argmax(A2,0)\n",
        "\n",
        "def get_accuracy(predictions,Y):\n",
        "  print(predictions,Y)\n",
        "  return np.sum(predictions==Y)/Y.size\n",
        "\n",
        "def gradient_descent(X, Y, iterations, alpha):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = back_prop(A1, A2, Y, W1, Z1, W2, Z2, X)\n",
        "        W1, b1, W2, b2 = update_params(dW1, db1, dW2, db2, W1, W2, b1, b2, alpha)\n",
        "        if i % 1 == 0:  # Print every 10 iterations\n",
        "            predictions = get_predictions(A2)\n",
        "            accuracy = get_accuracy(predictions, Y)\n",
        "            print(\"Iteration= \", i)\n",
        "            print(\"Accuracy= \", accuracy)\n",
        "    return W1, b1, W2, b2\n",
        "\n"
      ],
      "metadata": {
        "id": "kkX_swKBAlJ5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1,b1,W2,b2=gradient_descent(X_train,Y_train,200,0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l93XJvzG2eb",
        "outputId": "1dc36f3d-674c-419b-aa43-9de86ac60167"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 9 9 ... 8 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  0\n",
            "Accuracy=  0.1372093023255814\n",
            "[7 9 9 ... 8 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  1\n",
            "Accuracy=  0.1387596899224806\n",
            "[7 9 9 ... 8 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  2\n",
            "Accuracy=  0.13565891472868216\n",
            "[7 9 9 ... 8 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  3\n",
            "Accuracy=  0.1372093023255814\n",
            "[7 9 9 ... 8 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  4\n",
            "Accuracy=  0.13643410852713178\n",
            "[7 9 9 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  5\n",
            "Accuracy=  0.14263565891472868\n",
            "[7 9 9 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  6\n",
            "Accuracy=  0.15271317829457365\n",
            "[7 9 9 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  7\n",
            "Accuracy=  0.16279069767441862\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  8\n",
            "Accuracy=  0.17054263565891473\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  9\n",
            "Accuracy=  0.17674418604651163\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  10\n",
            "Accuracy=  0.18449612403100776\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  11\n",
            "Accuracy=  0.18604651162790697\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  12\n",
            "Accuracy=  0.19844961240310077\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  13\n",
            "Accuracy=  0.20310077519379846\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  14\n",
            "Accuracy=  0.21472868217054264\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  15\n",
            "Accuracy=  0.21627906976744185\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  16\n",
            "Accuracy=  0.22248062015503875\n",
            "[7 9 8 ... 7 8 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  17\n",
            "Accuracy=  0.2255813953488372\n",
            "[7 0 8 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  18\n",
            "Accuracy=  0.2310077519379845\n",
            "[7 0 8 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  19\n",
            "Accuracy=  0.23488372093023255\n",
            "[7 0 8 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  20\n",
            "Accuracy=  0.24263565891472869\n",
            "[7 0 8 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  21\n",
            "Accuracy=  0.24806201550387597\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  22\n",
            "Accuracy=  0.2496124031007752\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  23\n",
            "Accuracy=  0.2558139534883721\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  24\n",
            "Accuracy=  0.2589147286821705\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  25\n",
            "Accuracy=  0.26434108527131783\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  26\n",
            "Accuracy=  0.26744186046511625\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  27\n",
            "Accuracy=  0.2713178294573643\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  28\n",
            "Accuracy=  0.28604651162790695\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  29\n",
            "Accuracy=  0.28914728682170543\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  30\n",
            "Accuracy=  0.29534883720930233\n",
            "[7 0 7 ... 7 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  31\n",
            "Accuracy=  0.30077519379844964\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  32\n",
            "Accuracy=  0.30387596899224806\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  33\n",
            "Accuracy=  0.30697674418604654\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  34\n",
            "Accuracy=  0.31007751937984496\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  35\n",
            "Accuracy=  0.313953488372093\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  36\n",
            "Accuracy=  0.3147286821705426\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  37\n",
            "Accuracy=  0.32170542635658916\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  38\n",
            "Accuracy=  0.32790697674418606\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  39\n",
            "Accuracy=  0.3325581395348837\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  40\n",
            "Accuracy=  0.33488372093023255\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  41\n",
            "Accuracy=  0.3426356589147287\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  42\n",
            "Accuracy=  0.3457364341085271\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  43\n",
            "Accuracy=  0.3496124031007752\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  44\n",
            "Accuracy=  0.3573643410852713\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  45\n",
            "Accuracy=  0.35891472868217056\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  46\n",
            "Accuracy=  0.36046511627906974\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  47\n",
            "Accuracy=  0.36589147286821705\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  48\n",
            "Accuracy=  0.3697674418604651\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  49\n",
            "Accuracy=  0.37131782945736436\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  50\n",
            "Accuracy=  0.3767441860465116\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  51\n",
            "Accuracy=  0.37829457364341085\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  52\n",
            "Accuracy=  0.3829457364341085\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  53\n",
            "Accuracy=  0.3883720930232558\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  54\n",
            "Accuracy=  0.3930232558139535\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  55\n",
            "Accuracy=  0.3992248062015504\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  56\n",
            "Accuracy=  0.40310077519379844\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  57\n",
            "Accuracy=  0.4069767441860465\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  58\n",
            "Accuracy=  0.41007751937984493\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  59\n",
            "Accuracy=  0.413953488372093\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  60\n",
            "Accuracy=  0.4193798449612403\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  61\n",
            "Accuracy=  0.4248062015503876\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  62\n",
            "Accuracy=  0.42790697674418604\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  63\n",
            "Accuracy=  0.4325581395348837\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  64\n",
            "Accuracy=  0.43410852713178294\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  65\n",
            "Accuracy=  0.43333333333333335\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  66\n",
            "Accuracy=  0.44108527131782943\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  67\n",
            "Accuracy=  0.44651162790697674\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  68\n",
            "Accuracy=  0.4496124031007752\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  69\n",
            "Accuracy=  0.4511627906976744\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  70\n",
            "Accuracy=  0.45348837209302323\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  71\n",
            "Accuracy=  0.4565891472868217\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  72\n",
            "Accuracy=  0.45891472868217054\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  73\n",
            "Accuracy=  0.4627906976744186\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  74\n",
            "Accuracy=  0.4666666666666667\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  75\n",
            "Accuracy=  0.4697674418604651\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  76\n",
            "Accuracy=  0.4751937984496124\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  77\n",
            "Accuracy=  0.4782945736434108\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  78\n",
            "Accuracy=  0.47984496124031006\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  79\n",
            "Accuracy=  0.48372093023255813\n",
            "[7 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  80\n",
            "Accuracy=  0.48914728682170544\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  81\n",
            "Accuracy=  0.4937984496124031\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  82\n",
            "Accuracy=  0.4937984496124031\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  83\n",
            "Accuracy=  0.4945736434108527\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  84\n",
            "Accuracy=  0.49612403100775193\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  85\n",
            "Accuracy=  0.5\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  86\n",
            "Accuracy=  0.5031007751937985\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  87\n",
            "Accuracy=  0.5093023255813953\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  88\n",
            "Accuracy=  0.5100775193798449\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  89\n",
            "Accuracy=  0.5116279069767442\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  90\n",
            "Accuracy=  0.5108527131782946\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  91\n",
            "Accuracy=  0.5131782945736434\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  92\n",
            "Accuracy=  0.5155038759689923\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  93\n",
            "Accuracy=  0.5162790697674419\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  94\n",
            "Accuracy=  0.5193798449612403\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  95\n",
            "Accuracy=  0.5232558139534884\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  96\n",
            "Accuracy=  0.5248062015503876\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  97\n",
            "Accuracy=  0.5279069767441861\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  98\n",
            "Accuracy=  0.5333333333333333\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  99\n",
            "Accuracy=  0.5356589147286822\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  100\n",
            "Accuracy=  0.5372093023255814\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  101\n",
            "Accuracy=  0.5403100775193799\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  102\n",
            "Accuracy=  0.5434108527131783\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  103\n",
            "Accuracy=  0.5503875968992248\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  104\n",
            "Accuracy=  0.5565891472868217\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  105\n",
            "Accuracy=  0.5581395348837209\n",
            "[3 0 7 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  106\n",
            "Accuracy=  0.5589147286821705\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  107\n",
            "Accuracy=  0.5604651162790698\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  108\n",
            "Accuracy=  0.5658914728682171\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  109\n",
            "Accuracy=  0.5689922480620155\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  110\n",
            "Accuracy=  0.5705426356589147\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  111\n",
            "Accuracy=  0.5728682170542636\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  112\n",
            "Accuracy=  0.5751937984496124\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  113\n",
            "Accuracy=  0.5767441860465117\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  114\n",
            "Accuracy=  0.5782945736434109\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  115\n",
            "Accuracy=  0.5806201550387597\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  116\n",
            "Accuracy=  0.5852713178294574\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  117\n",
            "Accuracy=  0.5875968992248062\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  118\n",
            "Accuracy=  0.5883720930232558\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  119\n",
            "Accuracy=  0.5914728682170542\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  120\n",
            "Accuracy=  0.5945736434108527\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  121\n",
            "Accuracy=  0.5937984496124031\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  122\n",
            "Accuracy=  0.5945736434108527\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  123\n",
            "Accuracy=  0.5937984496124031\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  124\n",
            "Accuracy=  0.5945736434108527\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  125\n",
            "Accuracy=  0.5953488372093023\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  126\n",
            "Accuracy=  0.5984496124031008\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  127\n",
            "Accuracy=  0.6015503875968993\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  128\n",
            "Accuracy=  0.6031007751937985\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  129\n",
            "Accuracy=  0.603875968992248\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  130\n",
            "Accuracy=  0.6046511627906976\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  131\n",
            "Accuracy=  0.6069767441860465\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  132\n",
            "Accuracy=  0.6077519379844961\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  133\n",
            "Accuracy=  0.6085271317829457\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  134\n",
            "Accuracy=  0.610077519379845\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  135\n",
            "Accuracy=  0.6108527131782946\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  136\n",
            "Accuracy=  0.610077519379845\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  137\n",
            "Accuracy=  0.6116279069767442\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  138\n",
            "Accuracy=  0.6131782945736434\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  139\n",
            "Accuracy=  0.6147286821705427\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  140\n",
            "Accuracy=  0.6170542635658914\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  141\n",
            "Accuracy=  0.6186046511627907\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  142\n",
            "Accuracy=  0.6209302325581395\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  143\n",
            "Accuracy=  0.624031007751938\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  144\n",
            "Accuracy=  0.6248062015503876\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  145\n",
            "Accuracy=  0.6271317829457365\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  146\n",
            "Accuracy=  0.6286821705426356\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  147\n",
            "Accuracy=  0.6333333333333333\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  148\n",
            "Accuracy=  0.6341085271317829\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  149\n",
            "Accuracy=  0.6348837209302326\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  150\n",
            "Accuracy=  0.6341085271317829\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  151\n",
            "Accuracy=  0.6341085271317829\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  152\n",
            "Accuracy=  0.6341085271317829\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  153\n",
            "Accuracy=  0.6372093023255814\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  154\n",
            "Accuracy=  0.6372093023255814\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  155\n",
            "Accuracy=  0.6410852713178294\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  156\n",
            "Accuracy=  0.641860465116279\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  157\n",
            "Accuracy=  0.641860465116279\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  158\n",
            "Accuracy=  0.6426356589147287\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  159\n",
            "Accuracy=  0.6449612403100775\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  160\n",
            "Accuracy=  0.6472868217054264\n",
            "[3 0 1 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  161\n",
            "Accuracy=  0.6519379844961241\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  162\n",
            "Accuracy=  0.6534883720930232\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  163\n",
            "Accuracy=  0.6550387596899225\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  164\n",
            "Accuracy=  0.6565891472868217\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  165\n",
            "Accuracy=  0.6581395348837209\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  166\n",
            "Accuracy=  0.6589147286821705\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  167\n",
            "Accuracy=  0.6604651162790698\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  168\n",
            "Accuracy=  0.6643410852713179\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  169\n",
            "Accuracy=  0.6674418604651163\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  170\n",
            "Accuracy=  0.6689922480620155\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  171\n",
            "Accuracy=  0.6713178294573643\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  172\n",
            "Accuracy=  0.672093023255814\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  173\n",
            "Accuracy=  0.6751937984496124\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  174\n",
            "Accuracy=  0.6782945736434108\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  175\n",
            "Accuracy=  0.6775193798449612\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  176\n",
            "Accuracy=  0.6790697674418604\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  177\n",
            "Accuracy=  0.6806201550387597\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  178\n",
            "Accuracy=  0.6829457364341085\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  179\n",
            "Accuracy=  0.6829457364341085\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  180\n",
            "Accuracy=  0.6852713178294574\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  181\n",
            "Accuracy=  0.6868217054263566\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  182\n",
            "Accuracy=  0.6868217054263566\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  183\n",
            "Accuracy=  0.6891472868217055\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  184\n",
            "Accuracy=  0.6891472868217055\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  185\n",
            "Accuracy=  0.6914728682170542\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  186\n",
            "Accuracy=  0.6930232558139535\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  187\n",
            "Accuracy=  0.6945736434108527\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  188\n",
            "Accuracy=  0.6953488372093023\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  189\n",
            "Accuracy=  0.6961240310077519\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  190\n",
            "Accuracy=  0.6968992248062016\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  191\n",
            "Accuracy=  0.7\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  192\n",
            "Accuracy=  0.7007751937984497\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  193\n",
            "Accuracy=  0.7031007751937984\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  194\n",
            "Accuracy=  0.7046511627906977\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  195\n",
            "Accuracy=  0.7054263565891473\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  196\n",
            "Accuracy=  0.7062015503875969\n",
            "[3 0 8 ... 3 2 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  197\n",
            "Accuracy=  0.7093023255813954\n",
            "[3 0 8 ... 3 6 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  198\n",
            "Accuracy=  0.7131782945736435\n",
            "[3 0 8 ... 3 6 8] [3. 0. 8. ... 3. 4. 8.]\n",
            "Iteration=  199\n",
            "Accuracy=  0.713953488372093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks using Keras"
      ],
      "metadata": {
        "id": "tDxNpu_nPvt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "X_train = train_data.drop(columns=['label']).values\n",
        "y_train = train_data['label'].values\n",
        "X_test = test_data.values\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))  # Hidden layer with 10 units\n",
        "model.add(Dense(10, activation='softmax'))  # Output layer with 10 units for classification (digits 0-9)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions_probabilities = model.predict(X_test)\n",
        "predictions = np.argmax(predictions_probabilities, axis=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuhY_r2yHBRx",
        "outputId": "cb6f0620-4ed2-410c-ceb1-9fa519c44eed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "242/242 [==============================] - 2s 3ms/step - loss: 1.2902 - accuracy: 0.6086 - val_loss: nan - val_accuracy: 0.8233\n",
            "Epoch 2/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.8515 - val_loss: nan - val_accuracy: 0.8756\n",
            "Epoch 3/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8826 - val_loss: nan - val_accuracy: 0.8802\n",
            "Epoch 4/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8979 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 5/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.9056 - val_loss: nan - val_accuracy: 0.8988\n",
            "Epoch 6/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.9147 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 7/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2851 - accuracy: 0.9175 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 8/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.9218 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 9/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9274 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 10/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9275 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 11/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2367 - accuracy: 0.9328 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 12/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2300 - accuracy: 0.9332 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 13/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2220 - accuracy: 0.9363 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 14/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2136 - accuracy: 0.9374 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 15/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9387 - val_loss: nan - val_accuracy: 0.9209\n",
            "Epoch 16/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9412 - val_loss: nan - val_accuracy: 0.9233\n",
            "Epoch 17/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.1957 - accuracy: 0.9443 - val_loss: nan - val_accuracy: 0.9256\n",
            "Epoch 18/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9456 - val_loss: nan - val_accuracy: 0.9233\n",
            "Epoch 19/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.1862 - accuracy: 0.9457 - val_loss: nan - val_accuracy: 0.9233\n",
            "Epoch 20/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.9489 - val_loss: nan - val_accuracy: 0.9256\n",
            "Epoch 21/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9491 - val_loss: nan - val_accuracy: 0.9279\n",
            "Epoch 22/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.9499 - val_loss: nan - val_accuracy: 0.9291\n",
            "Epoch 23/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9533 - val_loss: nan - val_accuracy: 0.9233\n",
            "Epoch 24/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.9531 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 25/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9533 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 26/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9571 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 27/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9575 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 28/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9603 - val_loss: nan - val_accuracy: 0.9267\n",
            "Epoch 29/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9603 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 30/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1438 - accuracy: 0.9621 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 31/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.9620 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 32/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1365 - accuracy: 0.9648 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 33/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1358 - accuracy: 0.9628 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 34/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9660 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 35/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9646 - val_loss: nan - val_accuracy: 0.9209\n",
            "Epoch 36/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1253 - accuracy: 0.9682 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 37/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.1241 - accuracy: 0.9664 - val_loss: nan - val_accuracy: 0.9221\n",
            "Epoch 38/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.1223 - accuracy: 0.9685 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 39/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.1196 - accuracy: 0.9674 - val_loss: nan - val_accuracy: 0.9209\n",
            "Epoch 40/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9704 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 41/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1151 - accuracy: 0.9692 - val_loss: nan - val_accuracy: 0.9198\n",
            "Epoch 42/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1105 - accuracy: 0.9713 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 43/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1084 - accuracy: 0.9731 - val_loss: nan - val_accuracy: 0.9209\n",
            "Epoch 44/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1061 - accuracy: 0.9723 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 45/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.9735 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 46/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.9744 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 47/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9740 - val_loss: nan - val_accuracy: 0.9198\n",
            "Epoch 48/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9742 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 49/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9769 - val_loss: nan - val_accuracy: 0.9209\n",
            "Epoch 50/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9771 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 51/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9749 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 52/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9783 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 53/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9787 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 54/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9787 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 55/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9791 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 56/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9809 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 57/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9800 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 58/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9819 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 59/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9841 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 60/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9840 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 61/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9829 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 62/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9850 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 63/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9845 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 64/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.9844 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 65/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9849 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 66/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9854 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 67/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9869 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 68/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9857 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 69/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9871 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 70/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9866 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 71/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9873 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 72/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9888 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 73/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9885 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 74/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9882 - val_loss: nan - val_accuracy: 0.9198\n",
            "Epoch 75/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9888 - val_loss: nan - val_accuracy: 0.9198\n",
            "Epoch 76/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9895 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 77/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9903 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 78/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.9885 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 79/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9907 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 80/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9898 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 81/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9908 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 82/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9907 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 83/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9916 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 84/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9906 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 85/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.9937 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 86/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0464 - accuracy: 0.9915 - val_loss: nan - val_accuracy: 0.9186\n",
            "Epoch 87/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9926 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 88/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0434 - accuracy: 0.9924 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 89/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.9925 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 90/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9929 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 91/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0416 - accuracy: 0.9922 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 92/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9935 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 93/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0400 - accuracy: 0.9930 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 94/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0385 - accuracy: 0.9935 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 95/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9946 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 96/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9938 - val_loss: nan - val_accuracy: 0.9174\n",
            "Epoch 97/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.9944 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 98/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9953 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 99/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0337 - accuracy: 0.9947 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 100/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9950 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 101/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9933 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 102/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9942 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 103/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9952 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 104/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9964 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 105/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9955 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 106/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.9953 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 107/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9966 - val_loss: nan - val_accuracy: 0.9151\n",
            "Epoch 108/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9965 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 109/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9959 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 110/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9965 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 111/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9970 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 112/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9963 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 113/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9960 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 114/200\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9972 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 115/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9968 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 116/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 117/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0225 - accuracy: 0.9973 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 118/200\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9984 - val_loss: nan - val_accuracy: 0.9163\n",
            "Epoch 119/200\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0210 - accuracy: 0.9982 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 120/200\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.0209 - accuracy: 0.9979 - val_loss: nan - val_accuracy: 0.9116\n",
            "Epoch 121/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9982 - val_loss: nan - val_accuracy: 0.9105\n",
            "Epoch 122/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9975 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 123/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9983 - val_loss: nan - val_accuracy: 0.9081\n",
            "Epoch 124/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9977 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 125/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9982 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 126/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9988 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 127/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0175 - accuracy: 0.9986 - val_loss: nan - val_accuracy: 0.9081\n",
            "Epoch 128/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0171 - accuracy: 0.9983 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 129/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0164 - accuracy: 0.9991 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 130/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0161 - accuracy: 0.9990 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 131/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0154 - accuracy: 0.9991 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 132/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0159 - accuracy: 0.9988 - val_loss: nan - val_accuracy: 0.9035\n",
            "Epoch 133/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9991 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 134/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0145 - accuracy: 0.9990 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 135/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0146 - accuracy: 0.9987 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 136/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.9991 - val_loss: nan - val_accuracy: 0.9140\n",
            "Epoch 137/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9992 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 138/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 139/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9996 - val_loss: nan - val_accuracy: 0.9081\n",
            "Epoch 140/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9994 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 141/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 142/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9983 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 143/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 144/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9128\n",
            "Epoch 145/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 146/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9996 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 147/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: nan - val_accuracy: 0.9081\n",
            "Epoch 148/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9997 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 149/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 150/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0095 - accuracy: 0.9997 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 151/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: nan - val_accuracy: 0.8965\n",
            "Epoch 152/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 153/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 154/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 155/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0078 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 156/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9997 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 157/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 158/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 159/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9000\n",
            "Epoch 160/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: nan - val_accuracy: 0.9035\n",
            "Epoch 161/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 162/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 163/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 164/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9058\n",
            "Epoch 165/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 166/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9000\n",
            "Epoch 167/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 168/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 169/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 170/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 171/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 172/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 173/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 174/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 175/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.8977\n",
            "Epoch 176/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9035\n",
            "Epoch 177/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: nan - val_accuracy: 0.8965\n",
            "Epoch 178/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 179/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9070\n",
            "Epoch 180/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9035\n",
            "Epoch 181/200\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 182/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9035\n",
            "Epoch 183/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 184/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9000\n",
            "Epoch 185/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 186/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 187/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 188/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9047\n",
            "Epoch 189/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 190/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: nan - val_accuracy: 0.8977\n",
            "Epoch 191/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: nan - val_accuracy: 0.9093\n",
            "Epoch 192/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: nan - val_accuracy: 0.9000\n",
            "Epoch 193/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 194/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9012\n",
            "Epoch 195/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.8988\n",
            "Epoch 196/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 197/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9035\n",
            "Epoch 198/200\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 199/200\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9023\n",
            "Epoch 200/200\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.9000\n",
            "270/270 [==============================] - 1s 4ms/step\n",
            "[2 0 9 ... 6 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing a neural network from scratch and using a deep learning framework like Keras offer different advantages and considerations:\n",
        "\n",
        "1. **Customization vs. Simplicity**:\n",
        "    - **Writing from Scratch**: Building a neural network from scratch offers maximum customization. You have full control over every aspect of the network architecture, training loop, and optimization algorithms. However, it requires a deep understanding of neural networks and significant programming effort.\n",
        "    - **Using Keras**: Keras provides a high-level API for building neural networks. It offers simplicity and ease of use, allowing you to quickly prototype and experiment with different architectures. Keras abstracts away many low-level details, making it accessible to beginners and researchers who want to focus on model design and experimentation rather than implementation details.\n",
        "\n",
        "2. **Performance**:\n",
        "    - **Writing from Scratch**: Implementing neural networks efficiently from scratch can be challenging and time-consuming. It requires optimizing code for performance, especially for large datasets and complex models.\n",
        "    The accuracy is 71.39%.\n",
        "    - **Using Keras**: Keras leverages highly optimized backend libraries like TensorFlow or PyTorch for computations. These libraries are optimized for performance on CPUs and GPUs, resulting in efficient execution of neural network operations. Keras models can be easily scaled and deployed in production environments. The accuracy is 90%.\n",
        "\n",
        "3. **Community Support**:\n",
        "    - **Writing from Scratch**: While implementing neural networks from scratch can be a great learning experience, you may have limited resources and community support compared to using established frameworks.\n",
        "    - **Using Keras**: Keras has a large and active community of users and contributors. It provides extensive documentation, tutorials, and pre-trained models. You can leverage community-built tools and libraries to accelerate development and solve common problems.\n",
        "\n",
        "4. **Debugging and Testing**:\n",
        "    - **Writing from Scratch**: Debugging custom implementations can be challenging, especially when dealing with complex network architectures and optimization algorithms.\n",
        "    - **Using Keras**: Keras provides built-in support for debugging and testing neural networks. You can easily visualize model architectures, monitor training progress, and debug issues using tools like TensorBoard.\n"
      ],
      "metadata": {
        "id": "pnelLNOjEgbK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xh_ROfchEwwX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}